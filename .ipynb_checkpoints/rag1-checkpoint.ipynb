{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbca798-b96f-4c7d-b526-93083389ee28",
   "metadata": {},
   "source": [
    "# RAG Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dcf70d-9a01-46c6-8312-dfa02814c50a",
   "metadata": {},
   "source": [
    "To start, let's get GPT and its tokenizer set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffb40a1-6734-4ca7-be3a-de25c02df6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056c2ca-caa1-4e4f-90de-e375d65a325a",
   "metadata": {},
   "source": [
    "Now, set up an embedding model that will encode our content for the vector database. We will use FAISS to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705de6c7-0a0c-4e2c-a029-3ec151191e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# sample documents\n",
    "documents = [\n",
    "    \"RAG combines retrieval-based methods with generation-based models for improved text generation.\",\n",
    "    \"It retrieves relevant information from a large corpus to enhance the generation process.\",\n",
    "    \"By using FAISS, we efficiently search over the document embeddings.\",\n",
    "    \"GPT models are commonly used for generating natural language responses.\",\n",
    "    \"Sentence-Transformers generate high-quality document embeddings.\"\n",
    "]\n",
    "\n",
    "# convert documents into embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9df1e-2607-49b3-87a6-bcc03bc98ceb",
   "metadata": {},
   "source": [
    "Now we will add the documents to FAISS' index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d290dfbf-8ad2-41b3-b15e-988a0e9c5b66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "d = embeddings.shape[1]  # dimension of embeddings\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance metric\n",
    "index.add(np.array(embeddings))  # add embeddings to the index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88351a6-b0ee-4325-b1c7-cccd75f4c11a",
   "metadata": {},
   "source": [
    "We are now ready to ask the LLM questions.\n",
    "This happens in the following steps:\n",
    "# Ask our question ('query')\n",
    "# Create an embedding for our query. This will allow the vector database to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3fac7a-d5b3-45c9-a62a-da9fba26d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode([\"What is RAG?\"])[0]\n",
    "distances, indices = index.search(np.array([query_embedding]), k=5)  # Retrieve top 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530a95da-dacf-4305-a46f-2d82dd9b0a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c22ee8-acbc-47e5-a9f9-838cfeb00e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, -1, -1, -1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19140890-0846-4244-b903-371aecd5eab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

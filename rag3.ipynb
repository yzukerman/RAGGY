{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23485bf3-abcc-4b30-8158-76f38990130f",
   "metadata": {},
   "source": [
    "## Use PDF documents with RAG\n",
    "This tutorial downloads a set of PDF files from the Analog Devices website. You can use your own later. We will use these documents as our RAG knowledge base, with the goal of asking the LLM questions about information they contain.\n",
    "\n",
    "In this tutorial:\n",
    "1. Download the documents\n",
    "2. We will extract text from the documents and break it apart into chunks\n",
    "3. Vectorize the text chunks so the vector database can search them efficiently (semantic search)\n",
    "4. Load the vectors and text chunks into the database.\n",
    "\n",
    "### Document download\n",
    "We will download documents from [this page](https://www.analog.com/en/lp/001/blackfin-manuals.html) using Pandas' awesome capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c38f9f-8a7a-4f39-a431-8fddeb079e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-11-06 10:37:58--  https://www.analog.com/en/lp/001/blackfin-manuals.html\n",
      "Resolving www.analog.com (www.analog.com)... 23.197.199.106\n",
      "Connecting to www.analog.com (www.analog.com)|23.197.199.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘blackfin-manuals.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 3.26M\n",
      "    50K .......... .......... .......... .......... .......... 16.2M\n",
      "   100K .......... .......... ..                               3.38M=0.02s\n",
      "\n",
      "2024-11-06 10:37:58 (4.88 MB/s) - ‘blackfin-manuals.html’ saved [125639]\n",
      "\n",
      "Downloading: 100%|███████████████████████████| 91/91 [00:12<00:00,  7.13files/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "url = \"https://www.analog.com/en/lp/001/blackfin-manuals.html\"\n",
    "file_name = \"blackfin-manuals.html\"\n",
    "directory = \"docs2\"\n",
    "\n",
    "try:\n",
    "    # download the file\n",
    "    subprocess.run([\"wget\", \"-O\", file_name, url])\n",
    "    #subprocess.run([\"curl\", \"-L\", \"--tlsv1.2\", \"-O\", url], check=True)\n",
    "    parsed_url = urlparse(url)\n",
    "    file_name = os.path.basename(parsed_url.path)\n",
    "    # open the file\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # parse the webpage\n",
    "    soup = BeautifulSoup(file_content, \"html.parser\")\n",
    "    \n",
    "    # find pdf links\n",
    "    pdf_links = []\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        href = link[\"href\"]\n",
    "        if href.endswith(\".pdf\"):\n",
    "            pdf_links.append(href)\n",
    "\n",
    "    # make directory to store the pdfs in\n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "    \n",
    "    # download pdfs\n",
    "    for cur_pdf in tqdm(pdf_links, total=len(pdf_links), desc=\"Downloading\", unit=\"files\"):\n",
    "        response = requests.get(cur_pdf)\n",
    "        # get file name\n",
    "        parsed_url = urlparse(cur_pdf)\n",
    "        file_name = directory + \"/\" + os.path.basename(parsed_url.path)     \n",
    "        with open(file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "except Exception as err:\n",
    "    print(f\"An error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aec92f-8821-4cd5-83c1-71c93164bbb1",
   "metadata": {},
   "source": [
    "### Break documents into text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6338e1-6c33-4799-a0dc-04cd413e8a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs2\n"
     ]
    }
   ],
   "source": [
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e258b396-49c2-4193-a9e0-327596e27b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 91/91 [09:06<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='a\n",
      "W 5.0\n",
      "C/C++ Compiler and Library Manual\n",
      " for Blackfin® Processors\n",
      "Revision 5.4, January 2011\n",
      "Part Number\n",
      "82-000410-03\n",
      "Analog Devices, Inc.\n",
      "One T echnology Way\n",
      "Norwood, Mass. 02062-9106' metadata={'source': 'docs2/50_bf_cc_rtl_mn_rev_5.4.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# load the documents\n",
    "def load_documents():\n",
    "    document_loader = DirectoryLoader(directory, show_progress=True, loader_cls=PyPDFLoader)\n",
    "    return document_loader.lazy_load()\n",
    "\n",
    "# split documents to managable chunks\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap = 80,\n",
    "        length_function = len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "    \n",
    "documents = load_documents()\n",
    "#print(\"Loaded \" + str(len(documents)) + \" documents\")\n",
    "\n",
    "chunks = split_documents(documents)\n",
    "print(chunks[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e718fef9-28da-4e92-8634-40f7721cadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='switch turns on optimization, and -O0 turns off all optimizations.\n",
      "Invoke this switch by selecting the Enable optimization  check box in the \n",
      "Project Options  dialog box ( Compile : General page).\n",
      "-Oa\n",
      "The -Oa (automatic function inlining) sw itch enables the inline expansion \n",
      "of C/C++ functions, which are not necess arily declared inline in the source \n",
      "code. The amount of auto-inlining the compiler performs is controlled \n",
      "using the –Ov (optimize for speed versus size) switch ( on page 1-61 ). \n",
      "Therefore, the use of -Ov100 indicates that as many functions as possible \n",
      "will be auto-inlined, whereas –Ov0 prevents any function from being \n",
      "auto-inlined. Specifying -Oa implies the use of -O.\n",
      "Invoke this switch with the Automatic option button located in the' metadata={'source': 'docs2/50_bf_cc_rtl_mn_rev_5.4.pdf', 'page': 117}\n"
     ]
    }
   ],
   "source": [
    "print (chunks[330])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26ccba-e8e8-4ff3-bb2b-d40f8ee4d03e",
   "metadata": {},
   "source": [
    "Let's check how many chunks were generated from our documents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96db366-22eb-4fd6-baef-80a0fef304db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d8e3a2-f5fc-4d5e-abdc-3879e49fe6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switch turns on optimization, and -O0 turns off all optimizations.\n",
      "Invoke this switch by selecting the Enable optimization  check box in the \n",
      "Project Options  dialog box ( Compile : General page).\n",
      "-Oa\n",
      "The -Oa (automatic function inlining) sw itch enables the inline expansion \n",
      "of C/C++ functions, which are not necess arily declared inline in the source \n",
      "code. The amount of auto-inlining the compiler performs is controlled \n",
      "using the –Ov (optimize for speed versus size) switch ( on page 1-61 ). \n",
      "Therefore, the use of -Ov100 indicates that as many functions as possible \n",
      "will be auto-inlined, whereas –Ov0 prevents any function from being \n",
      "auto-inlined. Specifying -Oa implies the use of -O.\n",
      "Invoke this switch with the Automatic option button located in the\n",
      "Source: docs2/50_bf_cc_rtl_mn_rev_5.4.pdf\n",
      "Page: 117\n"
     ]
    }
   ],
   "source": [
    "print(chunks[330].page_content)\n",
    "print(\"Source: \" + chunks[330].metadata['source'])\n",
    "print(\"Page: \" + str(chunks[330].metadata['page']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78338f95-b54b-405e-85bd-895f7d387d70",
   "metadata": {},
   "source": [
    "Let's save the chunks in case we need them again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e8de91-fc93-4600-9c11-b771840ab478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"docs2/text_chunks.pkl\", \"wb\") as file:  # 'wb' means write in binary mode\n",
    "    pickle.dump(chunks, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c89720-5a03-45e2-9710-d418e28ef143",
   "metadata": {},
   "source": [
    "### Embedding the chunks\n",
    "Now we need to embed the chunks in the database.\n",
    "\n",
    "As you can see, each chunk consists of [Langchain Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document). \n",
    "Each Document has two elements:\n",
    "* ```page_content``` - the text of the chunk\n",
    "* ```metadata``` - a dictionary object, which in our case, contains the source document path and the page in which the chunk appeared.\n",
    "\n",
    "We will need to store this information in our vector database, Weaviate. Therefore, we will need to start with a very simple schema.\n",
    "* chunk_content\n",
    "* chunk_document_name\n",
    "* chunk_document_page\n",
    "\n",
    "Weaviate will handle the embedding for us using the model we specified (OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b742078e-929d-410b-b831-f7f52b3069ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_bfa71861716130b47f8adf2f44561700 error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 910835, Requested 92124. Please try again in 177ms. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:228: DeprecationWarning: Dep020: The `all_responses` attribute in the `BatchResults` object is deprecated and will be removed by Q4 2024. Please instead use the `errors` and `uuids` attributes.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_d5f1775babeacac62b447d1913134734 error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 898792, Requested 110861. Please try again in 579ms. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_7ef24ecab1f7ad5567a62cd4aa72c8e3 error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 64726. Please try again in 3.883s. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_aac116496aa56a3990c3aac988962b0a error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 999942, Requested 74449. Please try again in 4.463s. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_b6843d49d1b8fe20ead67d75961731e6 error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 983962, Requested 78580. Please try again in 3.752s. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_853ba68ff2ef98fbfbf26ec9512fe9bf error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 1000000, Requested 86633. Please try again in 5.197s. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 124 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_8db000eec02a646373c81c1ef9fd903d error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 992182, Requested 45867. Please try again in 2.282s. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_a0eab7d554f8373485d059b1cea5d114 error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 991787, Requested 47919. Please try again in 2.382s. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 62 seconds.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/weaviate/warnings.py:312: UserWarning: Bat005: Rate limit reached with error WeaviateInsertManyAllFailedError('Every object failed during insertion. Here is the set of all errors: connection to: OpenAI API failed with status: 429 request-id: req_4d8aad30266fe890d55301f8cdd23f9a error: Rate limit reached for text-embedding-ada-002 in organization org-TpPP0kLjXaLunR4pFEPauR5c on tokens per min (TPM): Limit 1000000, Used 967878, Requested 47919. Please try again in 947ms. Visit https://platform.openai.com/account/rate-limits to learn more.').\n",
      "            Sleeping for 124 seconds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate.classes.config as wc\n",
    "import weaviate\n",
    "import os\n",
    "\n",
    "headers = {\n",
    "    \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "}  # Replace with your OpenAI API key\n",
    "\n",
    "client = weaviate.connect_to_local(headers=headers)\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"ADI_DOCS\",\n",
    "    properties=[\n",
    "        wc.Property(name=\"chunk_content\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"chunk_document_name\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"chunk_document_page\", data_type=wc.DataType.INT),\n",
    "    ],\n",
    "    # Define the vectorizer module\n",
    "    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(),\n",
    "    # Define the generative module\n",
    "    generative_config=wc.Configure.Generative.openai()\n",
    ")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c081c8-2ecb-4170-9f29-9e1533f510aa",
   "metadata": {},
   "source": [
    "#### Load Weaviate with the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73a1fe2b-e31c-41b5-bfb7-6f59ebfcd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 68448/68448 [11:15<00:00, 101.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "try:    \n",
    "    # connect to database\n",
    "    client = weaviate.connect_to_local(headers=headers)\n",
    "           \n",
    "    # Get the collection\n",
    "    adi_docs = client.collections.get(\"ADI_DOCS\")\n",
    "    \n",
    "    cur_page = 0\n",
    "    cur_doc = \"\"\n",
    "    i = 0\n",
    "    \n",
    "    # Enter context manager\n",
    "    with adi_docs.batch.dynamic() as batch:\n",
    "        # Loop through the data\n",
    "        for chunk in tqdm(chunks, total=len(chunks)):\n",
    "            i +=1\n",
    "            # Convert data types\n",
    "\n",
    "            chunk_obj = {\n",
    "                \"chunk_content\": chunk.page_content,\n",
    "                \"chunk_document_name\": chunk.metadata['source'],\n",
    "                \"chunk_document_page\": chunk.metadata['page'],\n",
    "            }\n",
    "\n",
    "            if cur_doc != chunk.metadata['source']:\n",
    "                cur_doc = chunk.metadata['source']\n",
    "\n",
    "            if cur_page != chunk.metadata['page']:\n",
    "                cur_page = chunk.metadata['page']\n",
    "                \n",
    "            seed = cur_doc + \":\" + str(cur_page) + \":\" + str(i)\n",
    "    \n",
    "            # Add object to batch queue\n",
    "            batch.add_object(\n",
    "                properties=chunk_obj,\n",
    "                uuid=generate_uuid5(seed)\n",
    "                # references=reference_obj  # You can add references here\n",
    "            )\n",
    "            # Batcher automatically sends batches\n",
    "    \n",
    "    # Check for failed objects\n",
    "    if len(adi_docs.batch.failed_objects) > 0:\n",
    "        print(f\"Failed to import {len(adi_docs.batch.failed_objects)} objects\")\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b12dfb-29e8-4dd4-a7e6-b2e636ef3bf0",
   "metadata": {},
   "source": [
    "Let's verify that the records are in the vector database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1737e527-478b-4e0d-998e-2272f42c34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68448\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    # connect to database\n",
    "    client = weaviate.connect_to_local(headers=headers)\n",
    "           \n",
    "    # Get the collection\n",
    "    adi_docs = client.collections.get(\"ADI_DOCS\")\n",
    "    response = adi_docs.aggregate.over_all(total_count=True)\n",
    "    print(response.total_count)\n",
    "\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b847bf4-aa4b-4593-aaca-35b9abe2c4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
